---
layout: note
permalink: /360
title: AI Model Parameter - 원하는 응답을 생성하기
description: Temperature, Top-P, Penalty 등의 주요 parameter들을 통해 AI의 창의성, 일관성, 반복성을 조절할 수 있습니다.
date: 2025-07-28
---


## AI Model Parameter : AI 응답 생성을 조절하는 설정값들

- AI model parameter는 **AI가 응답을 생성하는 방식을 조절하는 설정값**들입니다.
    - 창의성, 일관성, 반복성, 길이 등 다양한 측면에서 AI의 행동을 제어할 수 있습니다.
    - 동일한 질문이라도 parameter 설정에 따라 완전히 다른 style의 답변을 받을 수 있습니다.

- **대부분의 AI service에서 공통으로 지원하는 주요 parameter**들을 이해하면 더 효과적으로 AI를 활용할 수 있습니다.
    - ChatGPT, Claude, Gemini 등 주요 AI service들이 유사한 parameter system을 사용합니다.
    - 각 parameter는 서로 다른 방식으로 응답의 특성에 영향을 미칩니다.


---


## AI 응답 생성 과정과 Parameter의 역할

- AI model은 **다음에 올 단어를 예측하는 방식**으로 text를 생성합니다.
    - 각 단어(token)에 대해 확률 점수를 계산하여 가장 적절한 것을 선택합니다.
    - parameter는 이 선택 과정에서 확률 분포를 조정하는 역할을 합니다.

- **확률 기반 선택 과정**을 통해 응답의 특성이 결정됩니다.
    - **높은 확률의 단어만 선택**하면 **예측 가능하고 안전한 응답**이 생성됩니다.
    - **낮은 확률의 단어도 포함**하면 **창의적이고 다양한 응답**이 나옵니다.
    - parameter는 이 balance를 조절하는 도구입니다.


### Token 선택과 확률 분포

- **각 위치에서 model은 수만 개의 candidate token 중 하나를 선택**해야 합니다.
    - "오늘 날씨가 ___" 다음에 올 수 있는 단어: "좋다", "나쁘다", "흐리다", "맑다" 등
    - 각 candidate에 대해 0~1 사이의 확률값이 계산됩니다.

- **parameter들은 이 확률 분포를 변형**하여 선택 결과를 조절합니다.
    - 확률이 높은 후보들만 고려하거나, 낮은 후보들도 포함시킬 수 있습니다.
    - 이미 사용된 단어들의 확률을 낮춰서 반복을 방지할 수도 있습니다.


---


## 핵심 생성 Parameter

- **temperature, top-p, top-k**는 AI 응답의 **창의성과 예측 가능성을 조절**하는 핵심 parameter들입니다.
    - 이 세 parameter가 AI 응답의 전반적인 "성격"을 결정합니다.
    - 용도에 따라 적절한 조합을 선택하는 것이 중요합니다.


### Temperature (온도)

- **temperature는 AI 응답의 무작위성과 창의성을 조절**하는 가장 중요한 parameter입니다.
    - 낮은 값 : 안전하고 예측 가능한 응답 (보수적).
    - 높은 값 : 창의적이고 다양한 응답 (모험적).

- **0.0~2.0 범위에서 설정**할 수 있으며, 일반적으로 0.0~1.0 사이를 사용합니다.
    - **0.0** : 항상 가장 확률이 높은 단어 선택 (완전 결정론적).
    - **0.3** : 안정적이면서도 약간의 변화가 있는 응답.
    - **0.7** : 창의적이지만 여전히 coherent한 응답.
    - **1.0** : 상당히 무작위적이고 예측하기 어려운 응답.

| Temperature | 용도 | 설명 |
| --- | --- | --- |
| 0.0 ~ 0.3 | **사실 확인과 번역** | 정확성을 우선시하는 응답, 일관되고 예측 가능한 결과 |
| 0.4 ~ 0.6 | **일반 대화와 설명** | 균형 잡힌 응답, 자연스러운 대화 가능 |
| 0.7 ~ 1.0 | **창작과 Brainstorming** | 높은 창의성, 예상치 못한 idea와 표현 |


### Top-P (Nucleus Sampling)

- **top-p는 고려할 단어들의 누적 확률 범위를 제한**합니다.
    - 확률이 높은 단어들부터 누적하여 p% 지점까지만 고려합니다.
    - 확률이 낮은 단어들을 자동으로 제외하여 품질을 보장합니다.

- **0.0~1.0 범위에서 설정**하며, 일반적으로 0.9~1.0을 사용합니다.
    - **0.1** : 상위 10% 확률 범위의 단어만 고려 (매우 보수적).
    - **0.5** : 상위 50% 확률 범위의 단어만 고려.
    - **0.9** : 상위 90% 확률 범위의 단어 고려 (표준 설정).
    - **1.0** : 모든 단어 고려 (제한 없음).

- **동적으로 후보 수가 조절**되는 것이 특징입니다.
    - 확실한 상황에서는 적은 후보만, 애매한 상황에서는 많은 후보를 고려합니다.
    - temperature와 함께 사용하여 더 정교한 제어가 가능합니다.


### Top-K

- **top-k는 고려할 단어의 개수를 고정적으로 제한**합니다.
    - 확률 순위가 높은 k개의 단어만 후보로 고려합니다.
    - 간단하고 직관적이지만 상황에 따른 유연성이 부족합니다.

- **일반적으로 20~100 범위에서 설정**합니다.
    - **1** : 항상 가장 확률이 높은 단어만 선택 (temperature 0과 동일).
    - **20** : 상위 20개 단어 중에서만 선택.
    - **50** : 상위 50개 단어 중에서만 선택 (일반적 설정).
    - **-1 또는 0** : 제한 없음 (모든 단어 고려).

- top-p와 비교했을 때, 고정된 개수를 사용하므로 예측하기 더 쉽다는 정점이 있지만, context에 대한 적응성이 떨어집니다.
    - 일반적으로 top-p가 더 자연스러운 결과를 생성합니다.


---


## 응답 제어 Parameter

- **system prompt, max token, stop sequence**는 **AI 응답의 형식과 길이를 제어**하는 parameter들입니다.
    - 생성 내용의 품질보다는 구조와 형식을 관리하는 데 중점을 둡니다.
    - 특정 용도나 application에 맞게 AI를 조율할 때 필수적입니다.


### System Prompt (system 지시 사항)

- **system prompt는 AI의 역할과 행동 방식을 정의**하는 특별한 지시 사항입니다.
    - 사용자 질문보다 우선순위가 높으며, 모든 응답에 지속적으로 영향을 미칩니다.
    - AI의 "성격"이나 "전문 분야"를 설정하는 용도로 사용합니다.

- 효과적인 system prompt 작성하기 위한 지침을 따르는 것이 좋습니다.
    - 명확하고 구체적인 역할을 부여하면 일관된 응답을 얻을 수 있습니다.
    - 응답 형식을 지정하면 원하는 구조의 답변을 받을 수 있습니다.
    - 제한 사항을 명시하면 부적절한 답변을 방지할 수 있습니다.

| 활용 예시 | Prompt | 결과 |
| --- | --- | --- |
| **교육용 AI** | "초등학생도 이해할 수 있게 쉽게 설명해주세요" | 일관된 교육 방식과 적절한 수준의 설명 유지 |
| **업무용 AI** | "비즈니스 전문가처럼 간결하고 데이터 기반으로 답변해주세요" | 전문적이고 효율적인 응답 제공 |
| **창작용 AI** | "창의적이고 상상력이 풍부한 storyteller가 되어주세요" | 독창적이고 흥미로운 내용 생성 |

- **system prompt는 AI의 기본 설정**으로, 사용자가 매번 입력할 필요 없이 지속적으로 적용됩니다.
    - 대화 시작 시 한 번만 설정하면 이후 모든 응답에 영향을 미칩니다.
    - AI의 behavior를 일관되게 유지하는 데 중요한 역할을 합니다.


### Max Token (최대 token 수)

- **max token은 AI가 생성할 수 있는 응답의 최대 길이를 제한**합니다.
    - token 수는 단어 수와 유사하지만 정확히 일치하지는 않습니다.
    - 일반적으로 영어 기준 1 token ≈ 0.75 단어 정도입니다.

- **적절한 길이 설정이 중요**합니다.
    - 너무 짧으면, 답변이 중간에 잘려서 불완전해집니다.
    - 너무 길면, 불필요하게 장황한 답변이 나오고 비용이 증가합니다.
    - 질문 유형에 맞는 적절한 길이를 설정해야 합니다.

| 용도별 적절한 길이 | 설정 범위 | 설명 |
| --- | --- | --- |
| **간단한 질문** | 50~100 tokens | 간결한 답변, 빠른 확인에 적합 |
| **일반적인 설명** | 200~500 tokens | 적당한 길이, 대부분의 질문에 적합 |
| **상세한 분석** | 1000~2000 tokens | 깊이 있는 내용, 복잡한 주제에 적합 |
| **긴 창작물** | 4000+ tokens | 장문 생성, 소설, 에세이 등에 적합 |

- **질문의 복잡도에 따라 적절한 길이를 설정**하는 것이 효과적입니다.
    - 긴 답변이 필요한 경우, max token을 늘려서 충분한 내용을 확보합니다.
    - 짧은 답변이 필요한 경우, max token을 줄여서 간결하게 만듭니다.


### Stop Sequence (정지 sequence)

- **stop sequence는 특정 문자열이 나타나면 생성을 중단**하는 기능입니다.
    - 원하는 지점에서 정확히 응답을 끝낼 수 있습니다.
    - 형식이 정해진 응답을 만들 때 유용합니다.

| 사용 예시 | 설정 | 설명 |
| --- | --- | --- |
| **목록 생성** | "\n\n" | 각 항목을 개별적으로 생성, 긴 목록 중 첫 번째 항목만 확인 |
| **대화 Simulation** | "User:", "AI:" | 역할극이나 대화 생성에서 적절한 지점에서 중단 |
| **Code 생성** | "```" | code block만 생성, programming 관련 질문에서 code 부분만 깔끔하게 받기 |

- stop sequence는 **예측 가능한 pattern이 있는 응답에서 사용**해야 합니다.
    - 단, "."과 같이 너무 일반적인 문자열은 피해야 합니다.
    - 여러 개의 stop sequence를 동시에 설정할 수도 있습니다.


---


## 반복 제어 Parameter

- **frequency penalty와 presence penalty**는 **AI 응답에서 단어나 구문의 반복을 제어**합니다.
    - 지나친 반복으로 인한 단조로움을 방지하고 다양성을 높입니다.
    - 창작이나 긴 text 생성에서 특히 유용합니다.


### Frequency Penalty (빈도 벌점)

- **frequency penalty는 이미 사용된 단어의 사용 빈도에 비례하여 벌점을 적용**합니다.
    - 많이 사용된 단어일수록 더 큰 벌점을 받아 선택 확률이 낮아집니다.
    - 점진적으로 반복을 줄여나가는 방식입니다.

- **-2.0~2.0 범위에서 설정**할 수 있습니다.
    - **0.0** : 벌점 없음 (기본값).
    - **0.5** : 적당한 반복 방지.
    - **1.0** : 강한 반복 방지.
    - **음수값** : 반복을 오히려 장려 (특수한 경우에만 사용).

- 일반적으로 반복을 줄이도록 설정하여 사용합니다.
    - **창작 writing** : 같은 표현의 반복을 줄여 문체를 다양화.
    - **brainstorming** : 다양한 idea 생성을 위해.
    - **요약** : 핵심 단어의 과도한 반복 방지.


### Presence Penalty (존재 벌점)

- **presence penalty는 한 번이라도 사용된 단어에 일정한 벌점을 적용**합니다.
    - 사용 빈도와 관계없이 동일한 벌점을 적용합니다.
    - 새로운 주제나 단어로의 전환을 촉진합니다.

- presence penalty가 frequency penalty보다 **더 급진적인 다양성**을 추구합니다.
    - **frequency** : "사과"를 3번 쓰면 3배의 벌점.
    - **presence** : "사과"를 1번 쓰든 10번 쓰든 동일한 벌점

- 주로 이미 사용된 단어를 반복하지 않고 새로운 단어로 전환해야 하는 경우에 사용됩니다.
    - **주제 전환** : 하나의 주제에 머무르지 않고 다양한 관점 제시.
    - **vocabulary 확장** : 더 풍부한 어휘 사용 유도.
    - **creative writing** : 예측하기 어려운 전개를 만들 때.


---


## Parameter 조합의 특성과 효과

- **목적에 따라 다른 parameter 조합이 다른 결과**를 만들어냅니다.
    - 단일 parameter보다는 여러 parameter의 조합이 응답의 전체적인 특성을 결정합니다.
    - 동일한 목적이라도 사용자에 따라 선호하는 설정이 다를 수 있습니다.


### 용도별 권장 설정

- **정확한 정보 제공** : 번역, 사실 확인, 기술 문서 작성 등.
    - Temperature : 0.0~0.3으로 설정하면 낮은 무작위성을 얻습니다.
    - Top-P : 0.1~0.5로 설정하면 높은 확률 단어만 사용됩니다.
    - Frequency/Presence Penalty: 0.0으로 설정하면 반복이 허용됩니다.

- **균형 잡힌 일반 대화** : 일반 질문 답변, 학습 도움, 상담 등.
    - Temperature : 0.5~0.7로 설정하면 적당한 창의성이 나타납니다.
    - Top-P : 0.9로 설정하면 표준적인 단어 선택이 이루어집니다.
    - Frequency Penalty : 0.3~0.5로 설정하면 적당한 반복 방지가 됩니다.

- **창의적 작업** : 소설 쓰기, idea 발상, 시 창작.
    - Temperature : 0.8~1.0으로 설정하면 높은 창의성이 나타납니다.
    - Top-P : 0.95~1.0으로 설정하면 다양한 단어가 허용됩니다.
    - Frequency/Presence Penalty : 0.5~1.0으로 설정하면 반복이 강하게 방지됩니다.


### Parameter 간 상호작용

- **temperature와 top-p의 관계**를 이해해야 합니다.
    - temperature가 낮으면 top-p 효과가 줄어듭니다.
    - temperature가 높으면 top-p가 더 중요해집니다.
    - 일반적으로 둘 중 하나만 주로 조정하고 나머지는 기본값 사용.

- **penalty parameter들의 균형**이 중요합니다.
    - 너무 높은 penalty : 어색하고 부자연스러운 문장.
    - 너무 낮은 penalty : 지루하고 반복적인 내용.
    - 0.3~0.7 범위에서 점진적으로 조정하는 것이 안전합니다.


### 실험과 최적화 방법

- **동일한 prompt로 다양한 설정을 test**해봅니다.
    - 같은 질문에 대해 여러 parameter 조합의 결과를 비교합니다.
    - 어떤 설정이 원하는 style에 가까운지 확인합니다.

- **점진적 조정**을 통해 최적점을 찾습니다.
    - 한 번에 하나의 parameter만 변경합니다.
    - 0.1~0.2씩 작은 단위로 조정합니다.
    - 극단적인 값은 피하고 중간 범위에서 시작합니다.

- **목적에 맞는 평가 기준**을 설정합니다.
    - 창의성 vs 정확성 중 어느 것이 더 중요한지 명확히 합니다.
    - 길이, 문체, 전문성 등 구체적인 요구 사항을 정의합니다.


---


## Parameter 사용 시 주의 사항

- **parameter 설정은 prompt 품질을 보완하는 역할**을 합니다.
    - 명확하고 구체적인 질문이 parameter보다 더 큰 영향을 미칩니다.
    - parameter는 fine-tuning 도구로서 전체적인 tone과 style을 조정합니다.


### 극단적인 설정의 효과

- **극단적인 parameter 값은 예상과 다른 결과**를 만들어낼 수 있습니다.
    - temperature 1.5 이상에서는 거의 무의미한 응답이 생성될 수 있습니다.
    - penalty 1.5 이상에서는 부자연스럽고 어색한 문장 구조가 나타납니다.
    - 여러 parameter를 동시에 극단값으로 설정하면 결과 예측이 어려워집니다.

- **설정 변경의 누적 효과**가 나타납니다.
    - 한 번에 여러 parameter를 변경하면 어떤 것이 영향을 미쳤는지 파악하기 어렵습니다.
    - 작은 단위로 점진적 변경을 하면 각 parameter의 개별 효과를 관찰할 수 있습니다.


### 비용과 성능 고려 사항

- **높은 creativity 설정은 더 많은 시행착오**를 필요로 합니다.
    - 원하는 결과를 얻기 위해 여러 번 시도해야 할 수 있습니다.
    - token 사용량과 비용이 증가할 수 있습니다.

- **max token 설정이 비용에 직접적인 영향**을 미칩니다.
    - 필요 이상으로 긴 설정은 불필요한 비용 증가를 가져옵니다.
    - 용도에 맞는 적절한 길이로 제한하는 것이 경제적입니다.


---


## Reference

- <https://platform.openai.com/docs/api-reference/completions>
- <https://docs.anthropic.com/claude/reference/messages>
- <https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/adjust-parameter-values>
- <https://www.promptingguide.ai/introduction/settings>
- <https://towardsdatascience.com/guide-to-chatgpts-advanced-settings-top-p-frequency-penalties-temperature-and-more-b70bae848069>

